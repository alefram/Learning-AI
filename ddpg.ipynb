{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e524b141",
   "metadata": {},
   "source": [
    "# DDPG algorithm in flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b15bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import jax.tree_util as jtu\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "from flax.training import train_state\n",
    "from flax import linen as nn  # Linen API\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "F_CPP_MIN_LOG_LEVEL=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a9a29",
   "metadata": {},
   "source": [
    "## Create necessary methods to the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a764cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random process N for action exploration\n",
    "def noise(noise_scale=0.1, key=random.PRNGKey(0), action_dim=2):\n",
    "    return noise_scale * jax.random.normal(key, (action_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca06c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the method to update model parameters\n",
    "\n",
    "# update critic\n",
    "@jax.jit\n",
    "def update_critic(model, states, actions, y):\n",
    "    def compute_critic_loss(params):\n",
    "        Q = model.apply_fn(params, states, actions)\n",
    "        return jnp.mean((Q - y)**2) #compute loss\n",
    "    \n",
    "    grad_fn = jax.grad(compute_critic_loss)\n",
    "    grads = grad_fn(model.params)\n",
    "    updated_model = model.apply_gradients(grads=grads)\n",
    "    return updated_model\n",
    "\n",
    "# udate actor\n",
    "@jtu.Partial(jax.jit, static_argnums=(2,))\n",
    "def update_actor(model, states, action_dim):\n",
    "    def compute_actor_loss(params):\n",
    "        actions = model.apply_fn(params, states, action_dim)\n",
    "        return -jnp.mean(actions)  # Compute the actor loss\n",
    "    \n",
    "    grad_fn = jax.grad(compute_actor_loss)\n",
    "    grads = grad_fn(model.params)\n",
    "    updated_model = model.apply_gradients(grads=grads)\n",
    "    return updated_model\n",
    "\n",
    "# Define the soft update function\n",
    "@jax.jit\n",
    "def soft_update(target_params, source_params, tau):\n",
    "    # Convert the source_params to a JAX-compatible data structure\n",
    "    source_params_tree = jtu.tree_map(lambda x: jnp.asarray(x), source_params)\n",
    "    target_params_tree = jtu.tree_map(lambda x: jnp.asarray(x), target_params)\n",
    "\n",
    "    # Compute the updated target parameters using a soft update\n",
    "    updated_params = jtu.tree_map(lambda x, y: tau * x + (1 - tau) * y, source_params_tree, target_params_tree)\n",
    "\n",
    "    return updated_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b1d002d-136a-4677-bc5e-6a29b376062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the replay buffer\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, buffer_size, batch_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer = deque(maxlen=self.buffer_size)\n",
    "\n",
    "    def add(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def sample_batch(self):\n",
    "        indices = jax.random.choice(key, len(self.buffer), shape=(self.batch_size,), replace=True)\n",
    "        batch = [self.buffer[i] for i in indices]\n",
    "\n",
    "        return zip(*batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a71636",
   "metadata": {},
   "source": [
    "## Create actor and critic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c7fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the actor and critic newtorks like multilayer perceptrons\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"critic model MLP\"\"\"\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, observations, actions):\n",
    "        x = jnp.concatenate([observations, actions], axis=-1)\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=1)(x)\n",
    "        return jnp.squeeze(x, axis=-1)\n",
    "    \n",
    "class Actor(nn.Module):\n",
    "    \"\"\"actor model MLP\"\"\"\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, action_dim):\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=action_dim)(x)\n",
    "        x = nn.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9e8513",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d0967cc-3733-4ef2-9b3c-6fc7e8694a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define environment\n",
    "env = gym.make(\"MountainCarContinuous-v0\")\n",
    "seed = 0\n",
    "key = random.PRNGKey(seed)\n",
    "action_dim = env.action_space.shape[0]\n",
    "state_dim = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af776785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                Actor Summary                                \u001b[0m\n",
      "┏━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                  \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│         │ Actor  │ - - 1        │ \u001b[2mfloat32\u001b[0m[1]   │                          │\n",
      "│         │        │   - 2        │              │                          │\n",
      "│         │        │ - 1          │              │                          │\n",
      "├─────────┼────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ Dense_0 │ Dense  │ - 1          │ \u001b[2mfloat32\u001b[0m[256] │ bias: \u001b[2mfloat32\u001b[0m[256]       │\n",
      "│         │        │ - 2          │              │ kernel: \u001b[2mfloat32\u001b[0m[2,256]   │\n",
      "│         │        │              │              │                          │\n",
      "│         │        │              │              │ \u001b[1m768 \u001b[0m\u001b[1;2m(3.1 KB)\u001b[0m             │\n",
      "├─────────┼────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ Dense_1 │ Dense  │ \u001b[2mfloat32\u001b[0m[256] │ \u001b[2mfloat32\u001b[0m[256] │ bias: \u001b[2mfloat32\u001b[0m[256]       │\n",
      "│         │        │              │              │ kernel: \u001b[2mfloat32\u001b[0m[256,256] │\n",
      "│         │        │              │              │                          │\n",
      "│         │        │              │              │ \u001b[1m65,792 \u001b[0m\u001b[1;2m(263.2 KB)\u001b[0m        │\n",
      "├─────────┼────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ Dense_2 │ Dense  │ \u001b[2mfloat32\u001b[0m[256] │ \u001b[2mfloat32\u001b[0m[1]   │ bias: \u001b[2mfloat32\u001b[0m[1]         │\n",
      "│         │        │              │              │ kernel: \u001b[2mfloat32\u001b[0m[256,1]   │\n",
      "│         │        │              │              │                          │\n",
      "│         │        │              │              │ \u001b[1m257 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m             │\n",
      "├─────────┼────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m       Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m66,817 \u001b[0m\u001b[1;2m(267.3 KB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
      "└─────────┴────────┴──────────────┴──────────────┴──────────────────────────┘\n",
      "\u001b[1m                                                                             \u001b[0m\n",
      "\u001b[1m                     Total Parameters: 66,817 \u001b[0m\u001b[1;2m(267.3 KB)\u001b[0m\u001b[1m                     \u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[3m                                 Critic Summary                                 \u001b[0m\n",
      "┏━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                 \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│         │ Critic │ - \u001b[2mfloat32\u001b[0m[1,1] │ \u001b[2mfloat32\u001b[0m[1]     │                         │\n",
      "│         │        │ - \u001b[2mfloat32\u001b[0m[1,2] │                │                         │\n",
      "├─────────┼────────┼────────────────┼────────────────┼─────────────────────────┤\n",
      "│ Dense_0 │ Dense  │ \u001b[2mfloat32\u001b[0m[1,3]   │ \u001b[2mfloat32\u001b[0m[1,256] │ bias: \u001b[2mfloat32\u001b[0m[256]      │\n",
      "│         │        │                │                │ kernel: \u001b[2mfloat32\u001b[0m[3,256]  │\n",
      "│         │        │                │                │                         │\n",
      "│         │        │                │                │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m          │\n",
      "├─────────┼────────┼────────────────┼────────────────┼─────────────────────────┤\n",
      "│ Dense_1 │ Dense  │ \u001b[2mfloat32\u001b[0m[1,256] │ \u001b[2mfloat32\u001b[0m[1,256] │ bias: \u001b[2mfloat32\u001b[0m[256]      │\n",
      "│         │        │                │                │ kernel:                 │\n",
      "│         │        │                │                │ \u001b[2mfloat32\u001b[0m[256,256]        │\n",
      "│         │        │                │                │                         │\n",
      "│         │        │                │                │ \u001b[1m65,792 \u001b[0m\u001b[1;2m(263.2 KB)\u001b[0m       │\n",
      "├─────────┼────────┼────────────────┼────────────────┼─────────────────────────┤\n",
      "│ Dense_2 │ Dense  │ \u001b[2mfloat32\u001b[0m[1,256] │ \u001b[2mfloat32\u001b[0m[1,1]   │ bias: \u001b[2mfloat32\u001b[0m[1]        │\n",
      "│         │        │                │                │ kernel: \u001b[2mfloat32\u001b[0m[256,1]  │\n",
      "│         │        │                │                │                         │\n",
      "│         │        │                │                │ \u001b[1m257 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m            │\n",
      "├─────────┼────────┼────────────────┼────────────────┼─────────────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m67,073 \u001b[0m\u001b[1;2m(268.3 KB)\u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\n",
      "└─────────┴────────┴────────────────┴────────────────┴─────────────────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                      Total Parameters: 67,073 \u001b[0m\u001b[1;2m(268.3 KB)\u001b[0m\u001b[1m                       \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Randomly initialize critic network Q(s, a|θ_Q ) and actor μ(s|θ_μ ) with weights θ_Q and θ_μ .\n",
    "critic_params = Critic().init(key, jnp.zeros((1, state_dim)), jnp.zeros((1, action_dim)))\n",
    "actor_params = Actor().init(key, jnp.zeros((1, state_dim)), action_dim)\n",
    "\n",
    "# define optimizers\n",
    "actor_optimizer = optax.adam(learning_rate=100)\n",
    "actor_opt_state = actor_optimizer.init(actor_params)\n",
    "\n",
    "critic_optimizer = optax.adam(learning_rate=100)\n",
    "critic_opt_state = critic_optimizer.init(critic_params)\n",
    "\n",
    "# Initialize the training state for flax porpuses\n",
    "critic = train_state.TrainState.create(\n",
    "    apply_fn=Critic().apply,\n",
    "    params=critic_params,\n",
    "    tx=critic_optimizer\n",
    ")\n",
    "\n",
    "actor = train_state.TrainState.create(\n",
    "    apply_fn=Actor().apply,\n",
    "    params=actor_params,\n",
    "    tx=actor_optimizer,\n",
    ")\n",
    "\n",
    "print(Actor().tabulate(key, (1, state_dim), action_dim))\n",
    "print(Critic().tabulate(key, jnp.ones((1,action_dim)), jnp.ones((1,state_dim))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4fede34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize target network Q_0_target and μ_0_target with weights θ_Q_target ← θ_Q , θ_μ_target ← θ_μ\n",
    "target_critic_params = critic_params\n",
    "target_actor_params = actor_params\n",
    "\n",
    "# Initialize the training state for flax porpuses\n",
    "target_critic = train_state.TrainState.create(\n",
    "    apply_fn=Critic().apply,\n",
    "    params=target_critic_params,\n",
    "    tx=critic_optimizer\n",
    ")\n",
    "\n",
    "target_actor = train_state.TrainState.create(\n",
    "    apply_fn=Actor().apply,\n",
    "    params=target_actor_params,\n",
    "    tx=actor_optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80f4b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize replay buffer R\n",
    "buffer_size = 100000\n",
    "batch_size = 10\n",
    "\n",
    "buffer = ReplayBuffer(buffer_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "670e041a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████                                                       | 1/10 [01:25<12:53, 85.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([array([-95.73358], dtype=float32)], maxlen=100)\n",
      "Episode: 0 Average reward: -95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████▏                                                | 2/10 [02:51<11:24, 85.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([array([-95.73358], dtype=float32), array([-95.82894], dtype=float32)], maxlen=100)\n",
      "Episode: 1 Average reward: -95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████▎                                          | 3/10 [04:17<10:01, 85.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([array([-95.73358], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32)], maxlen=100)\n",
      "Episode: 2 Average reward: -95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████▍                                    | 4/10 [05:44<08:38, 86.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([array([-95.73358], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32)], maxlen=100)\n",
      "Episode: 3 Average reward: -95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████▌                              | 5/10 [07:11<07:12, 86.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([array([-95.73358], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32)], maxlen=100)\n",
      "Episode: 4 Average reward: -95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████▌                        | 6/10 [08:38<05:46, 86.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([array([-95.73358], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32)], maxlen=100)\n",
      "Episode: 5 Average reward: -95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████▋                  | 7/10 [10:04<04:19, 86.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([array([-95.73358], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32)], maxlen=100)\n",
      "Episode: 6 Average reward: -95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████▊            | 8/10 [11:30<02:53, 86.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([array([-95.73358], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32)], maxlen=100)\n",
      "Episode: 7 Average reward: -95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████▉      | 9/10 [12:55<01:25, 85.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([array([-95.73358], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32)], maxlen=100)\n",
      "Episode: 8 Average reward: -95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 10/10 [14:17<00:00, 85.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([array([-95.73358], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32), array([-95.82894], dtype=float32)], maxlen=100)\n",
      "Episode: 9 Average reward: -95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#initialize parameters\n",
    "episodes = 10\n",
    "gamma = 0.1\n",
    "tau = 0.001\n",
    "max_episode_steps = 100\n",
    "env = gym.wrappers.RecordEpisodeStatistics(env, deque_size=max_episode_steps)\n",
    "\n",
    "episodes_reward = []\n",
    "\n",
    "#train loop\n",
    "for i in tqdm(range(episodes)):\n",
    "    # Initialize a random process N for action exploration\n",
    "    N = noise(0.1, key, action_dim)\n",
    "    # Receive initial observation state s 1\n",
    "    state, info = env.reset(seed=seed)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Select action a_t = μ(s t |θ μ ) + N t according to the current policy and exploration noise\n",
    "        action = actor.apply_fn(actor.params, state, action_dim) + N\n",
    "\n",
    "        # Execute action a t and observe reward r t and observe new state s t+1\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        # Store transition (s t , a t , r t , s t+1 ) in R\n",
    "        transition = (state, action, reward, observation)\n",
    "        \n",
    "        # buffer.append(transition)\n",
    "        buffer.add(transition)\n",
    "\n",
    "        # Sample a random minibatch of N transitions (s i , a i , r i , s i+1 ) from R\n",
    "        states, actions, rewards, next_states = buffer.sample_batch()\n",
    "\n",
    "        # Set y = r  + γQ^0 (s_{i+1} , μ^0 (s_{i+1} |θ^μ )|θ^Q ) P\n",
    "        target_action = target_actor.apply_fn(target_actor_params, jnp.asarray(next_states, dtype=jnp.float16), action_dim)\n",
    "        target_q = target_critic.apply_fn(target_critic_params, jnp.asarray(next_states, dtype=jnp.float16), jnp.asarray(target_action, dtype=jnp.float16))\n",
    "\n",
    "        y = reward + gamma * (1 - terminated) * target_q\n",
    "\n",
    "        # Update critic by minimizing the loss\n",
    "        critic = update_critic(critic, jnp.asarray(states, dtype=jnp.float16), jnp.asarray(actions, dtype=jnp.float16), jnp.asarray(y, jnp.float16))\n",
    "\n",
    "        # Update the actor policy using the sampled gradient:\n",
    "        actor = update_actor(actor, jnp.asarray(states, dtype=jnp.float16), action_dim)\n",
    "\n",
    "        # Update the target networks:\n",
    "        target_actor_params = soft_update(target_actor_params, actor.params, tau)\n",
    "        target_critic_params = soft_update(target_critic_params, critic.params, tau)\n",
    "       \n",
    "        # update if the environment is done and the current observation\n",
    "        done = terminated or truncated\n",
    "        # state = observation\n",
    "\n",
    "    print(env.return_queue)\n",
    "    episodes_reward.append(env.return_queue[-1])\n",
    "    \n",
    "    avg_reward = int(np.mean(env.return_queue))\n",
    "    print(\"Episode:\", i, \"Average reward:\", avg_reward)\n",
    "\n",
    "    \n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496fd34a",
   "metadata": {},
   "source": [
    "## Visualizing the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "217629c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards_to_plot = [rewards for rewards in episodes_reward]\n",
    "\n",
    "plt.plot(range(episodes), episodes_reward)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Rewards over episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c8e8a",
   "metadata": {},
   "source": [
    "## Stable baselines training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d9b4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cb3097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m action_noise \u001b[38;5;241m=\u001b[39m NormalActionNoise(mean\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros(n_actions), sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mones(n_actions))\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m DDPG(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, action_noise\u001b[38;5;241m=\u001b[39maction_noise, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mddpg_MountainCarContinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m vec_env \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_env()\n",
      "File \u001b[0;32m~/repos/notebooks/venv/lib/python3.10/site-packages/stable_baselines3/ddpg/ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDDPG,\n\u001b[1;32m    116\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDDPG:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/notebooks/venv/lib/python3.10/site-packages/stable_baselines3/td3/td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[1;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/notebooks/venv/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:331\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/repos/notebooks/venv/lib/python3.10/site-packages/stable_baselines3/td3/td3.py:188\u001b[0m, in \u001b[0;36mTD3.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# Optimize the critics\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 188\u001b[0m \u001b[43mcritic_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Delayed policy updates\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/notebooks/venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/notebooks/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=100, log_interval=10)\n",
    "model.save(\"ddpg_MountainCarContinuous\")\n",
    "vec_env = model.get_env()\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpg_MountainCarContinuous\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    env.render(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea2c206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
