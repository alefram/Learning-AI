{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e524b141",
   "metadata": {},
   "source": [
    "# DDPG algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64325f1",
   "metadata": {},
   "source": [
    "## Initialize actor and critic network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b15bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "from flax import linen as nn  # Linen API\n",
    "from collections import deque\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"MountainCarContinuous-v0\")\n",
    "seed = 0\n",
    "key = random.PRNGKey(seed)\n",
    "\n",
    "F_CPP_MIN_LOG_LEVEL=0\n",
    "action_dim = env.action_space.shape[0]\n",
    "state_dim = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2713383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "[[0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#create the actor and critic newtorks like multilayer perceptrons\n",
    "\n",
    "# class Critic(nn.Module):\n",
    "#     def setup(self):\n",
    "#         self.q = nn.Dense(features=1)\n",
    "\n",
    "#     def __call__(self, obs, act):\n",
    "#         x = jnp.concatenate([obs, act], axis=-1)\n",
    "#         q = self.q(x)\n",
    "#         return jnp.squeeze(q, axis=-1)\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    \"\"\"critic model MLP\"\"\"\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, observations, actions):\n",
    "        x = jnp.concatenate([observations, actions], axis=-1)\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=1)(x)\n",
    "        return jnp.squeeze(x, axis=-1)\n",
    "    \n",
    "class Actor(nn.Module):\n",
    "    \"\"\"actor model MLP\"\"\"\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=action_dim)(x)\n",
    "        x = nn.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3eb7881",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                Actor Summary                                \u001b[0m\n",
      "┏━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                  \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│         │ Actor  │ - 1          │ \u001b[2mfloat32\u001b[0m[1]   │                          │\n",
      "│         │        │ - 2          │              │                          │\n",
      "├─────────┼────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ Dense_0 │ Dense  │ - 1          │ \u001b[2mfloat32\u001b[0m[256] │ bias: \u001b[2mfloat32\u001b[0m[256]       │\n",
      "│         │        │ - 2          │              │ kernel: \u001b[2mfloat32\u001b[0m[2,256]   │\n",
      "│         │        │              │              │                          │\n",
      "│         │        │              │              │ \u001b[1m768 \u001b[0m\u001b[1;2m(3.1 KB)\u001b[0m             │\n",
      "├─────────┼────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ Dense_1 │ Dense  │ \u001b[2mfloat32\u001b[0m[256] │ \u001b[2mfloat32\u001b[0m[256] │ bias: \u001b[2mfloat32\u001b[0m[256]       │\n",
      "│         │        │              │              │ kernel: \u001b[2mfloat32\u001b[0m[256,256] │\n",
      "│         │        │              │              │                          │\n",
      "│         │        │              │              │ \u001b[1m65,792 \u001b[0m\u001b[1;2m(263.2 KB)\u001b[0m        │\n",
      "├─────────┼────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ Dense_2 │ Dense  │ \u001b[2mfloat32\u001b[0m[256] │ \u001b[2mfloat32\u001b[0m[1]   │ bias: \u001b[2mfloat32\u001b[0m[1]         │\n",
      "│         │        │              │              │ kernel: \u001b[2mfloat32\u001b[0m[256,1]   │\n",
      "│         │        │              │              │                          │\n",
      "│         │        │              │              │ \u001b[1m257 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m             │\n",
      "├─────────┼────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m       Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m66,817 \u001b[0m\u001b[1;2m(267.3 KB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
      "└─────────┴────────┴──────────────┴──────────────┴──────────────────────────┘\n",
      "\u001b[1m                                                                             \u001b[0m\n",
      "\u001b[1m                     Total Parameters: 66,817 \u001b[0m\u001b[1;2m(267.3 KB)\u001b[0m\u001b[1m                     \u001b[0m\n",
      "\n",
      "\n",
      "actor parameters:\n",
      " FrozenDict({\n",
      "    params: {\n",
      "        Dense_0: {\n",
      "            bias: (256,),\n",
      "            kernel: (2, 256),\n",
      "        },\n",
      "        Dense_1: {\n",
      "            bias: (256,),\n",
      "            kernel: (256, 256),\n",
      "        },\n",
      "        Dense_2: {\n",
      "            bias: (1,),\n",
      "            kernel: (256, 1),\n",
      "        },\n",
      "    },\n",
      "})\n",
      "\n",
      "\u001b[3m                                 Critic Summary                                 \u001b[0m\n",
      "┏━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                 \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│         │ Critic │ - \u001b[2mfloat32\u001b[0m[1,1] │ \u001b[2mfloat32\u001b[0m[1]     │                         │\n",
      "│         │        │ - \u001b[2mfloat32\u001b[0m[1,2] │                │                         │\n",
      "├─────────┼────────┼────────────────┼────────────────┼─────────────────────────┤\n",
      "│ Dense_0 │ Dense  │ \u001b[2mfloat32\u001b[0m[1,3]   │ \u001b[2mfloat32\u001b[0m[1,256] │ bias: \u001b[2mfloat32\u001b[0m[256]      │\n",
      "│         │        │                │                │ kernel: \u001b[2mfloat32\u001b[0m[3,256]  │\n",
      "│         │        │                │                │                         │\n",
      "│         │        │                │                │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m          │\n",
      "├─────────┼────────┼────────────────┼────────────────┼─────────────────────────┤\n",
      "│ Dense_1 │ Dense  │ \u001b[2mfloat32\u001b[0m[1,256] │ \u001b[2mfloat32\u001b[0m[1,256] │ bias: \u001b[2mfloat32\u001b[0m[256]      │\n",
      "│         │        │                │                │ kernel:                 │\n",
      "│         │        │                │                │ \u001b[2mfloat32\u001b[0m[256,256]        │\n",
      "│         │        │                │                │                         │\n",
      "│         │        │                │                │ \u001b[1m65,792 \u001b[0m\u001b[1;2m(263.2 KB)\u001b[0m       │\n",
      "├─────────┼────────┼────────────────┼────────────────┼─────────────────────────┤\n",
      "│ Dense_2 │ Dense  │ \u001b[2mfloat32\u001b[0m[1,256] │ \u001b[2mfloat32\u001b[0m[1,1]   │ bias: \u001b[2mfloat32\u001b[0m[1]        │\n",
      "│         │        │                │                │ kernel: \u001b[2mfloat32\u001b[0m[256,1]  │\n",
      "│         │        │                │                │                         │\n",
      "│         │        │                │                │ \u001b[1m257 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m            │\n",
      "├─────────┼────────┼────────────────┼────────────────┼─────────────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m67,073 \u001b[0m\u001b[1;2m(268.3 KB)\u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\n",
      "└─────────┴────────┴────────────────┴────────────────┴─────────────────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                      Total Parameters: 67,073 \u001b[0m\u001b[1;2m(268.3 KB)\u001b[0m\u001b[1m                       \u001b[0m\n",
      "\n",
      "\n",
      "critic parameters:\n",
      " FrozenDict({\n",
      "    params: {\n",
      "        Dense_0: {\n",
      "            bias: (256,),\n",
      "            kernel: (3, 256),\n",
      "        },\n",
      "        Dense_1: {\n",
      "            bias: (256,),\n",
      "            kernel: (256, 256),\n",
      "        },\n",
      "        Dense_2: {\n",
      "            bias: (1,),\n",
      "            kernel: (256, 1),\n",
      "        },\n",
      "    },\n",
      "}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Randomly initialize critic network Q(s, a|θ_Q ) and actor μ(s|θ_μ ) with weights θ_Q and θ_μ .\n",
    "critic = Critic()\n",
    "critic_params = critic.init(key, jnp.zeros((1,action_dim)), jnp.zeros((1,state_dim)))\n",
    "actor = Actor()\n",
    "actor_params = actor.init(key, jnp.zeros((1, state_dim)))\n",
    "\n",
    "check_critic = jax.tree_util.tree_map(lambda x: x.shape, critic_params) #checking critic params\n",
    "check_actor = jax.tree_util.tree_map(lambda x: x.shape, actor_params) #checking actor params\n",
    "\n",
    "print(actor.tabulate(key, (1, state_dim) ))\n",
    "print(\"actor parameters:\\n\", check_actor)\n",
    "\n",
    "print(critic.tabulate(key, jnp.ones((1,action_dim)), jnp.ones((1,state_dim))))\n",
    "print(\"critic parameters:\\n\", check_critic, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93662f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critic forward test: [0.13340816] \n",
      "\n",
      "actor forward test: [[-0.4034107]]\n"
     ]
    }
   ],
   "source": [
    "#foward example with the initial  parameters \n",
    "# the parameters never store in the model\n",
    "critic_forward = critic.apply(critic_params, jnp.ones((1, action_dim)), jnp.ones((1, state_dim)) )\n",
    "actor_forward = actor.apply(actor_params, jnp.ones((1, state_dim)))\n",
    "\n",
    "print(\"critic forward test:\", critic_forward, \"\\n\")\n",
    "print(\"actor forward test:\", actor_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80f4b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize target network Q_0_target and μ_0_target with weights \n",
    "# θ_Q_target ← θ_Q , θ_μ_target ← θ_μ\n",
    "target_critic = Critic()\n",
    "target_actor = Actor()\n",
    "\n",
    "target_critic_params = critic_params\n",
    "target_actor_params = actor_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb5437a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize replay buffer R\n",
    "buffer_size = 1000\n",
    "buffer = deque(maxlen=buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cdb04edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.47260767  0.        ]\n",
      "[-0.02058423]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a random process N for action exploration\n",
    "def noise(noise_scale=0.1):\n",
    "    return noise_scale * jax.random.normal(key, (action_dim,))\n",
    "# Receive initial observation state s 1\n",
    "state, info = env.reset(seed=seed)\n",
    "print(state)\n",
    "N = noise(0.1)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dfcaba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [-0.07492159] \n",
      "\n",
      "next state: [-0.47748625 -0.00193688] \n",
      "\n",
      "buffer: deque([(array([-0.47260767,  0.        ], dtype=float32), Array([-0.07492159], dtype=float32), -0.0005613243991732519, array([-0.473101  , -0.00049333], dtype=float32)), (array([-0.47260767,  0.        ], dtype=float32), Array([-0.07492159], dtype=float32), -0.0005613243991732519, array([-0.474084  , -0.00098299], dtype=float32)), (array([-0.47260767,  0.        ], dtype=float32), Array([-0.07492159], dtype=float32), -0.0005613243991732519, array([-0.47554937, -0.00146537], dtype=float32)), (array([-0.47260767,  0.        ], dtype=float32), Array([-0.07492159], dtype=float32), -0.0005613243991732519, array([-0.47748625, -0.00193688], dtype=float32))], maxlen=1000) \n",
      "\n",
      "minibatch: [(array([-0.47260767,  0.        ], dtype=float32), Array([-0.07492159], dtype=float32), -0.0005613243991732519, array([-0.47554937, -0.00146537], dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "# Select action a_t = μ(s t |θ μ ) + N t according to the current policy and exploration noise\n",
    "action = noise() + actor.apply(actor_params, state)\n",
    "# action = env.action_space.sample()\n",
    "print(\"action:\", action, \"\\n\")\n",
    "\n",
    "# Execute action a t and observe reward r t and observe new state s t+1\n",
    "next_state, reward, terminated, done, info = env.step(action)\n",
    "print(\"next state:\", next_state, \"\\n\")\n",
    "\n",
    "# Store transition (s t , a t , r t , s t+1 ) in R\n",
    "transition = (state, action, reward, next_state)\n",
    "buffer.append(transition)\n",
    "print(\"buffer:\", buffer, \"\\n\")\n",
    "\n",
    "# Sample a random minibatch of N transitions (s i , a i , r i , s i+1 ) from R\n",
    "batch_size = 1\n",
    "indices = jax.random.choice(key, len(buffer), shape=(batch_size,), replace=False)\n",
    "minibatch = [buffer[i] for i in indices]\n",
    "print(\"minibatch:\", minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3583ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.016791953\n"
     ]
    }
   ],
   "source": [
    "# Set y i = r i + γQ 0 (s i+1 , μ 0 (s i+1 |θ μ )|θ Q ) P\n",
    "u_target = target_actor.apply(target_actor_params, next_state)\n",
    "Q_target = target_critic.apply(target_critic_params, next_state, u_target)\n",
    "gamma = 0.1\n",
    "\n",
    "y = reward + gamma * (1 - done) * Q_target\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "afeb5317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021232113\n"
     ]
    }
   ],
   "source": [
    "# Update critic by minimizing the loss: L = N 1 i (y i − Q(s i , a i |θ Q ) 2 )\n",
    "Q = critic.apply(critic_params, state, action)\n",
    "loss = ((Q - y)**2).mean() #compute loss\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
