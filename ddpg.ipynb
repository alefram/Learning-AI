{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a77f0c-f949-4d14-8bf6-86c28a897c77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# DDPG algorithm in flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7bb8bac-c5ac-4072-88c0-a124a2151112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from collections import deque\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "import jax.tree_util as jtu\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "from flax.training import train_state, orbax_utils\n",
    "from flax import linen as nn  # Linen API\n",
    "\n",
    "from tqdm import tqdm\n",
    "import orbax.checkpoint\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "F_CPP_MIN_LOG_LEVEL=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5691d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt_dir = './agent' # create the agent folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a9a29",
   "metadata": {},
   "source": [
    "## Usefull Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a764cb53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#random process N for action exploration \n",
    "class OUActionNoise:\n",
    "    def __init__(self, key, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * jnp.sqrt(self.dt) * jax.random.normal(key, shape=self.mean.shape)\n",
    "        )\n",
    "\n",
    "        self.x_prev = x\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = jnp.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca06c72c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the method to update model parameters\n",
    "\n",
    "# update critic\n",
    "@jax.jit\n",
    "def update_critic(model, states, actions, y):\n",
    "    def compute_critic_loss(params):\n",
    "        Q = model.apply_fn(params, states, actions)\n",
    "        \n",
    "        return jnp.mean((Q - y)**2) #compute loss\n",
    "    \n",
    "    loss, grads = jax.value_and_grad(compute_critic_loss)(model.params)\n",
    "    updated_model = model.apply_gradients(grads=grads)\n",
    "   \n",
    "    return updated_model, loss\n",
    "\n",
    "# udate actor\n",
    "@jtu.Partial(jax.jit, static_argnums=(3,))\n",
    "def update_actor(model, critic, states, action_dim):\n",
    "    def compute_actor_loss(params):\n",
    "        actions = model.apply_fn(params, states, action_dim)\n",
    "        \n",
    "        Q = critic.apply_fn(critic.params, states, actions)\n",
    "\n",
    "        return -jnp.mean(Q)  # Compute the actor loss\n",
    "\n",
    "    loss, grads = jax.value_and_grad(compute_actor_loss)(model.params)\n",
    "    updated_model = model.apply_gradients(grads=grads)\n",
    "\n",
    "    return updated_model, loss\n",
    "\n",
    "# Define the soft update function\n",
    "@jax.jit\n",
    "def soft_update(target_params, source_params, tau):\n",
    "    # Convert the source_params to a JAX-compatible data structure\n",
    "    source_params_tree = jtu.tree_map(lambda x: jnp.asarray(x), source_params)\n",
    "    target_params_tree = jtu.tree_map(lambda x: jnp.asarray(x), target_params)\n",
    "\n",
    "    # Compute the updated target parameters using a soft update\n",
    "    updated_params = jtu.tree_map(lambda x, y: tau * x + (1 - tau) * y,\n",
    "                                  source_params_tree, target_params_tree)\n",
    "\n",
    "    return updated_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb8988-b86d-4a4a-b5d5-16bc53c509e7",
   "metadata": {},
   "source": [
    "## Define ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2b1d002d-136a-4677-bc5e-6a29b376062b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the replay buffer\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, buffer_size, batch_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer = deque(maxlen=self.buffer_size)\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "    def add(self, transition):\n",
    "        if len(self.buffer) >= self.buffer_size:\n",
    "            self.buffer.pop(0)\n",
    "            \n",
    "        self.buffer.append(transition)\n",
    "        \n",
    "        self.buffer_counter += 1\n",
    "\n",
    "    #TODO: finish to update fix the batching\n",
    "    def sample_batch(self, key):\n",
    "        record_range = min(self.buffer_counter, self.buffer_size)\n",
    "        \n",
    "        # if record_range < self.batch_size:\n",
    "        #     print(len(self.buffer))\n",
    "        #     raise ValueError(\"Replay buffer is too small to sample.\")\n",
    "            \n",
    "        indices = jax.random.choice(\n",
    "            key, \n",
    "            record_range,\n",
    "            shape=(self.batch_size,), replace=True\n",
    "        )\n",
    "        \n",
    "        batch = [self.buffer[i] for i in indices]\n",
    "        \n",
    "        return zip(*batch)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a71636",
   "metadata": {},
   "source": [
    "## Define actor and critic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44c7fe1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create the actor and critic newtorks like multilayer perceptrons\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"critic model MLP\"\"\"\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, observations, actions):\n",
    "        x = jnp.concatenate([observations, actions], axis=-1)\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=1)(x)\n",
    "        return jnp.squeeze(x, axis=-1)\n",
    "    \n",
    "class Actor(nn.Module):\n",
    "    \"\"\"actor model MLP\"\"\"\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, action_dim):\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=action_dim)(x)\n",
    "        x = nn.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9e8513",
   "metadata": {},
   "source": [
    "## Define algorithm parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "618e7ec1-2ec7-4230-b34d-e693c7bea28b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define key\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "key = jax.random.PRNGKey(seed)\n",
    "\n",
    "key, actor_key, critic_key = jax.random.split(key, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "3d0967cc-3733-4ef2-9b3c-6fc7e8694a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define environment and parameters\n",
    "env = gym.make(\"InvertedPendulum-v4\")\n",
    "action_dim = env.action_space.shape[0]\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "#initialize parameters\n",
    "episodes = 100\n",
    "gamma = 0.99 #discount factor 0:nearly rewards, 1:future rewards\n",
    "tau = 0.001 #polyak between 0-1 updating target network\n",
    "max_episode_steps = 1000\n",
    "buffer_size = int(1e6) #memory size\n",
    "batch_size = 64 #The number of experiences sampled from the replay buffer\n",
    "actor_learning_rate = 1e-3\n",
    "critic_learning_rate = 1e-4\n",
    "std_dev = 0.2  #scale of the noise for random process N for action exploration\n",
    "noise = OUActionNoise(key, mean=jnp.zeros(1), std_deviation=float(std_dev) * jnp.ones(1))\n",
    "\n",
    "env = gym.wrappers.RecordEpisodeStatistics(env, deque_size=max_episode_steps)\n",
    "\n",
    "if os.path.exists(ckpt_dir):\n",
    "    shutil.rmtree(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5afde-d37d-4a65-8af7-316be0f76dbf",
   "metadata": {},
   "source": [
    "## Initialize models and buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "af776785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Randomly initialize critic network Q(s, a|θ_Q ) and actor μ(s|θ_μ ) with weights θ_Q and θ_μ .\n",
    "obs, _ = env.reset();\n",
    "\n",
    "# Initialize the training state actor and critic models\n",
    "critic = train_state.TrainState.create(\n",
    "    apply_fn=Critic().apply,\n",
    "    params=Critic().init(critic_key, obs, env.action_space.sample()), #init critic parameters\n",
    "    tx=optax.adamw(learning_rate=critic_learning_rate, weight_decay=1e-2) #define optimizer\n",
    ")\n",
    "\n",
    "actor = train_state.TrainState.create(\n",
    "    apply_fn=Actor().apply,\n",
    "    params=Actor().init(actor_key, obs, action_dim), #init actor parameters\n",
    "    tx=optax.adam(learning_rate=actor_learning_rate) #define optimizer\n",
    ")\n",
    "\n",
    "# to save agent\n",
    "config = {'dimensions': jnp.array([5,3]), 'name': 'actor'}\n",
    "ckpt = {'model': actor, 'config': config, 'data': actor.params}\n",
    "\n",
    "# print(Actor().tabulate(key, obs, action_dim))\n",
    "# print(Critic().tabulate(key, obs, env.action_space.sample()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "b4fede34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize target network Q_0_target and μ_0_target with weights \n",
    "# θ_Q_target ← θ_Q , θ_μ_target ← θ_μ\n",
    "\n",
    "# Initialize the training state for flax porpuses\n",
    "target_critic = train_state.TrainState.create(\n",
    "    apply_fn=Critic().apply,\n",
    "    params=critic.params,\n",
    "    tx=optax.adamw(learning_rate=critic_learning_rate, weight_decay=1e-2)\n",
    ")\n",
    "\n",
    "target_actor = train_state.TrainState.create(\n",
    "    apply_fn=Actor().apply,\n",
    "    params=actor.params,\n",
    "    tx=optax.adam(learning_rate=actor_learning_rate)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "80f4b370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize replay buffer R\n",
    "buffer = ReplayBuffer(buffer_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0dbd9c-a50a-477b-b860-f7a39d12ac9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "670e041a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1\n",
      "Average reward => 32 Episode len => 32 Critic loss => 0.6322334 Actor loss => -1.0385733 \n",
      "\n",
      "Episode: 2\n",
      "Average reward => 20 Episode len => 8 Critic loss => 0.57368207 Actor loss => -1.4298896 \n",
      "\n",
      "Episode: 3\n",
      "Average reward => 23 Episode len => 31 Critic loss => 0.53784835 Actor loss => -2.2453227 \n",
      "\n",
      "Episode: 4\n",
      "Average reward => 19 Episode len => 5 Critic loss => 0.62696123 Actor loss => -2.3583531 \n",
      "\n",
      "Episode: 5\n",
      "Average reward => 16 Episode len => 5 Critic loss => 0.52092093 Actor loss => -2.2540622 \n",
      "\n",
      "Episode: 6\n",
      "Average reward => 14 Episode len => 5 Critic loss => 0.31177646 Actor loss => -2.2951317 \n",
      "\n",
      "Episode: 7\n",
      "Average reward => 12 Episode len => 4 Critic loss => 0.37063438 Actor loss => -2.2018507 \n",
      "\n",
      "Episode: 8\n",
      "Average reward => 11 Episode len => 4 Critic loss => 0.34382838 Actor loss => -2.1632857 \n",
      "\n",
      "Episode: 9\n",
      "Average reward => 10 Episode len => 4 Critic loss => 0.2662295 Actor loss => -2.2300713 \n",
      "\n",
      "Episode: 10\n",
      "Average reward => 10 Episode len => 4 Critic loss => 0.2323378 Actor loss => -2.3348577 \n",
      "\n",
      "Episode: 11\n",
      "Average reward => 9 Episode len => 4 Critic loss => 0.21449576 Actor loss => -2.2959661 \n",
      "\n",
      "Episode: 12\n",
      "Average reward => 9 Episode len => 4 Critic loss => 0.28214094 Actor loss => -2.3370516 \n",
      "\n",
      "Episode: 13\n",
      "Average reward => 8 Episode len => 4 Critic loss => 0.23974562 Actor loss => -2.5076208 \n",
      "\n",
      "Episode: 14\n",
      "Average reward => 8 Episode len => 4 Critic loss => 0.21164629 Actor loss => -2.4173234 \n",
      "\n",
      "Episode: 15\n",
      "Average reward => 8 Episode len => 4 Critic loss => 0.23539539 Actor loss => -2.511014 \n",
      "\n",
      "Episode: 16\n",
      "Average reward => 7 Episode len => 3 Critic loss => 0.2354486 Actor loss => -2.4717886 \n",
      "\n",
      "Episode: 17\n",
      "Average reward => 7 Episode len => 3 Critic loss => 0.16952659 Actor loss => -2.556075 \n",
      "\n",
      "Episode: 18\n",
      "Average reward => 7 Episode len => 3 Critic loss => 0.18955222 Actor loss => -2.7456868 \n",
      "\n",
      "Episode: 19\n",
      "Average reward => 7 Episode len => 3 Critic loss => 0.16427179 Actor loss => -2.718913 \n",
      "\n",
      "Episode: 20\n",
      "Average reward => 6 Episode len => 3 Critic loss => 0.15521026 Actor loss => -2.7630837 \n",
      "\n",
      "Episode: 21\n",
      "Average reward => 6 Episode len => 3 Critic loss => 0.1958791 Actor loss => -2.744093 \n",
      "\n",
      "Episode: 22\n",
      "Average reward => 6 Episode len => 3 Critic loss => 0.15241253 Actor loss => -2.7775693 \n",
      "\n",
      "Episode: 23\n",
      "Average reward => 6 Episode len => 3 Critic loss => 0.19092487 Actor loss => -2.7985225 \n",
      "\n",
      "Episode: 24\n",
      "Average reward => 6 Episode len => 3 Critic loss => 0.12618949 Actor loss => -2.9714527 \n",
      "\n",
      "Episode: 25\n",
      "Average reward => 6 Episode len => 3 Critic loss => 0.15339416 Actor loss => -2.9538627 \n",
      "\n",
      "Episode: 26\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.14739473 Actor loss => -2.8482933 \n",
      "\n",
      "Episode: 27\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.1916277 Actor loss => -2.950163 \n",
      "\n",
      "Episode: 28\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.16187257 Actor loss => -3.0556622 \n",
      "\n",
      "Episode: 29\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.14128369 Actor loss => -3.1422925 \n",
      "\n",
      "Episode: 30\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.15988389 Actor loss => -3.187281 \n",
      "\n",
      "Episode: 31\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.13183495 Actor loss => -3.2403789 \n",
      "\n",
      "Episode: 32\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.15275493 Actor loss => -3.251841 \n",
      "\n",
      "Episode: 33\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.15181306 Actor loss => -3.141073 \n",
      "\n",
      "Episode: 34\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.14593074 Actor loss => -3.1799006 \n",
      "\n",
      "Episode: 35\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.15030049 Actor loss => -3.4299686 \n",
      "\n",
      "Episode: 36\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.13500524 Actor loss => -3.2212586 \n",
      "\n",
      "Episode: 37\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.14187202 Actor loss => -3.32678 \n",
      "\n",
      "Episode: 38\n",
      "Average reward => 5 Episode len => 3 Critic loss => 0.14238918 Actor loss => -3.3448913 \n",
      "\n",
      "Episode: 39\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.11339327 Actor loss => -3.519902 \n",
      "\n",
      "Episode: 40\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.12529752 Actor loss => -3.503542 \n",
      "\n",
      "Episode: 41\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.1248623 Actor loss => -3.5148754 \n",
      "\n",
      "Episode: 42\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.18073714 Actor loss => -3.5656836 \n",
      "\n",
      "Episode: 43\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.10695514 Actor loss => -3.5941205 \n",
      "\n",
      "Episode: 44\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.117636114 Actor loss => -3.8072953 \n",
      "\n",
      "Episode: 45\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.094251096 Actor loss => -3.7049694 \n",
      "\n",
      "Episode: 46\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.10121136 Actor loss => -3.8784719 \n",
      "\n",
      "Episode: 47\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.08791823 Actor loss => -3.9826462 \n",
      "\n",
      "Episode: 48\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.11889156 Actor loss => -3.8933969 \n",
      "\n",
      "Episode: 49\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.10810003 Actor loss => -3.849432 \n",
      "\n",
      "Episode: 50\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.11271209 Actor loss => -4.0909863 \n",
      "\n",
      "Episode: 51\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.08953537 Actor loss => -4.042783 \n",
      "\n",
      "Episode: 52\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.099251494 Actor loss => -3.907889 \n",
      "\n",
      "Episode: 53\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.10790759 Actor loss => -3.95285 \n",
      "\n",
      "Episode: 54\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.09554607 Actor loss => -4.0224476 \n",
      "\n",
      "Episode: 55\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.13366011 Actor loss => -4.1501794 \n",
      "\n",
      "Episode: 56\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.115324646 Actor loss => -4.2340784 \n",
      "\n",
      "Episode: 57\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.12795569 Actor loss => -4.248483 \n",
      "\n",
      "Episode: 58\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.12147056 Actor loss => -4.064324 \n",
      "\n",
      "Episode: 59\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.0966408 Actor loss => -4.436187 \n",
      "\n",
      "Episode: 60\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.108650886 Actor loss => -4.228267 \n",
      "\n",
      "Episode: 61\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.10503002 Actor loss => -4.099025 \n",
      "\n",
      "Episode: 62\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.061597258 Actor loss => -4.4366326 \n",
      "\n",
      "Episode: 63\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.082913786 Actor loss => -4.5934134 \n",
      "\n",
      "Episode: 64\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.08628856 Actor loss => -4.276971 \n",
      "\n",
      "Episode: 65\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.11856525 Actor loss => -4.4337993 \n",
      "\n",
      "Episode: 66\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.10019496 Actor loss => -4.330288 \n",
      "\n",
      "Episode: 67\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.079634026 Actor loss => -4.388848 \n",
      "\n",
      "Episode: 68\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.09586049 Actor loss => -4.4685817 \n",
      "\n",
      "Episode: 69\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.0906313 Actor loss => -4.6014905 \n",
      "\n",
      "Episode: 70\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.09659296 Actor loss => -4.157782 \n",
      "\n",
      "Episode: 71\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.07688649 Actor loss => -4.606103 \n",
      "\n",
      "Episode: 72\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.07690353 Actor loss => -4.32063 \n",
      "\n",
      "Episode: 73\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.100957885 Actor loss => -4.3748655 \n",
      "\n",
      "Episode: 74\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.08552162 Actor loss => -4.9995914 \n",
      "\n",
      "Episode: 75\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.08310346 Actor loss => -4.4706783 \n",
      "\n",
      "Episode: 76\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.07582639 Actor loss => -4.6909676 \n",
      "\n",
      "Episode: 77\n",
      "Average reward => 4 Episode len => 3 Critic loss => 0.07638328 Actor loss => -4.676775 \n",
      "\n",
      "Episode: 78\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.09353342 Actor loss => -4.503644 \n",
      "\n",
      "Episode: 79\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.08008164 Actor loss => -4.623798 \n",
      "\n",
      "Episode: 80\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.0725677 Actor loss => -4.44519 \n",
      "\n",
      "Episode: 81\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.063450284 Actor loss => -4.8526645 \n",
      "\n",
      "Episode: 82\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.08872008 Actor loss => -4.9198174 \n",
      "\n",
      "Episode: 83\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.07487258 Actor loss => -4.530586 \n",
      "\n",
      "Episode: 84\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.06985429 Actor loss => -4.601259 \n",
      "\n",
      "Episode: 85\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.05302499 Actor loss => -4.9856586 \n",
      "\n",
      "Episode: 86\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.063484654 Actor loss => -4.693616 \n",
      "\n",
      "Episode: 87\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.06864485 Actor loss => -4.978512 \n",
      "\n",
      "Episode: 88\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.05096169 Actor loss => -4.988992 \n",
      "\n",
      "Episode: 89\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.057086453 Actor loss => -4.9120736 \n",
      "\n",
      "Episode: 90\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.0638212 Actor loss => -4.8677673 \n",
      "\n",
      "Episode: 91\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.07907459 Actor loss => -4.7535996 \n",
      "\n",
      "Episode: 92\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.063555196 Actor loss => -5.234678 \n",
      "\n",
      "Episode: 93\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.07729541 Actor loss => -4.852709 \n",
      "\n",
      "Episode: 94\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.06319089 Actor loss => -4.961008 \n",
      "\n",
      "Episode: 95\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.06707371 Actor loss => -4.7976046 \n",
      "\n",
      "Episode: 96\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.06667256 Actor loss => -5.356744 \n",
      "\n",
      "Episode: 97\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.07644964 Actor loss => -4.6981916 \n",
      "\n",
      "Episode: 98\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.06731161 Actor loss => -4.9587307 \n",
      "\n",
      "Episode: 99\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.073239036 Actor loss => -4.6494665 \n",
      "\n",
      "Episode: 100\n",
      "Average reward => 3 Episode len => 3 Critic loss => 0.0682902 Actor loss => -5.0349307 \n",
      "\n",
      "Execution time: 37.445507287979126\n"
     ]
    }
   ],
   "source": [
    "episodes_reward = []\n",
    "critic_loss = 0\n",
    "actor_loss = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(episodes):\n",
    "    # Initialize a random process N for action exploration we do this in => noise()\n",
    "    \n",
    "    # Receive initial observation state s_1\n",
    "    state, info = env.reset()\n",
    "    done = False\n",
    "    episode_len = 0\n",
    "    \n",
    "    while not done:\n",
    "        \n",
    "        # Select action a_t = μ(s t |θ μ ) + N t according to the current policy and exploration noise\n",
    "        action = actor.apply_fn(actor.params, state, action_dim) + noise()\n",
    "        \n",
    "        # Execute action a t and observe reward r t and observe new state s t+1\n",
    "        observation, reward, terminated, truncated, _ = env.step(action)\n",
    "                \n",
    "        # Store transition (s t , a t , r t , s t+1 ) in R\n",
    "        transition = (state, action, reward, observation)\n",
    "        buffer.add(transition)\n",
    "                    \n",
    "        # Sample a random minibatch of N transitions (s i , a i , r i , s i+1 ) from R\n",
    "        # key, subkey = jax.random.split(key)\n",
    "        states, actions, rewards, next_states = buffer.sample_batch(key)\n",
    "\n",
    "        # Set y = r  + γQ^0 (s_{i+1} , μ^0 (s_{i+1} |θ^μ )|θ^Q ) P\n",
    "        target_action = target_actor.apply_fn(target_actor.params,\n",
    "                                              jnp.asarray(next_states),\n",
    "                                              action_dim)\n",
    "\n",
    "\n",
    "        target_q = target_critic.apply_fn(target_critic.params,\n",
    "                                          jnp.asarray(next_states),\n",
    "                                          jnp.asarray(target_action))\n",
    "\n",
    "        rewards = jnp.asarray(rewards)\n",
    "\n",
    "        # y = rewards + gamma * (1 - terminated) * target_q #corregir es un arreglo revisar paper\n",
    "        y = rewards + gamma * target_q #corregir es un arreglo revisar paper\n",
    "\n",
    "\n",
    "        # Update critic by minimizing the loss\n",
    "        critic, critic_loss = update_critic(critic,\n",
    "                                            jnp.asarray(states),\n",
    "                                            jnp.asarray(actions),\n",
    "                                            jnp.asarray(y))\n",
    "\n",
    "        # Update the actor policy using the sampled gradient:\n",
    "        actor, actor_loss = update_actor(actor,\n",
    "                                         critic,\n",
    "                                         jnp.asarray(states),\n",
    "                                         action_dim)\n",
    "\n",
    "        # Update the target networks:\n",
    "        target_actor_params = soft_update(target_actor.params, actor.params, tau)\n",
    "        target_critic_params = soft_update(target_critic.params, critic.params, tau)\n",
    "        \n",
    "        # update if the environment is done and the current observation\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        episode_len += 1\n",
    "        state = observation\n",
    "\n",
    "\n",
    "    episodes_reward.append(env.return_queue[-1]) \n",
    "    avg_reward = int(np.mean(env.return_queue))\n",
    "    \n",
    "\n",
    "    print(\"Episode:\", i+1)\n",
    "    \n",
    "    print(\"Average reward =>\", avg_reward,\n",
    "          \"Episode len =>\", episode_len,\n",
    "          \"Critic loss =>\", critic_loss, \n",
    "          \"Actor loss =>\", actor_loss, \"\\n\") \n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "# execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time:\", execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d04fcd1-8596-4ac2-bc2b-4b7c625a7c02",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77b42bf7-a946-4eb7-aa50-d4537c3fbda0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save agent\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(ckpt)\n",
    "orbax_checkpointer.save('./agent', ckpt, save_args=save_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496fd34a",
   "metadata": {},
   "source": [
    "## Visualizing the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "217629c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards_to_plot = [rewards for rewards in episodes_reward]\n",
    "\n",
    "plt.plot(range(episodes), episodes_reward)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Reward')\n",
    "plt.grid()\n",
    "plt.title('Rewards over episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ff1e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore agent\n",
    "raw_restored = orbax_checkpointer.restore('./agent')\n",
    "actor_params = raw_restored['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53364c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"InvertedPendulum-v4\", render_mode=\"human\")\n",
    "\n",
    "observation, info = env.reset()\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = actor.apply_fn(actor_params, observation, env.action_space.shape[0])\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
