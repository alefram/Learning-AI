{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e524b141",
   "metadata": {},
   "source": [
    "# DDPG algorithm in flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b15bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import jax.tree_util as jtu\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "from flax.training import train_state\n",
    "from flax import linen as nn  # Linen API\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make(\"MountainCarContinuous-v0\", max_episode_steps=100)\n",
    "seed = 0\n",
    "key = random.PRNGKey(seed)\n",
    "\n",
    "F_CPP_MIN_LOG_LEVEL=0\n",
    "action_dim = env.action_space.shape[0]\n",
    "state_dim = env.observation_space.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ec141b2",
   "metadata": {},
   "source": [
    "## Create the actor and critic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2713383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the actor and critic newtorks like multilayer perceptrons\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"critic model MLP\"\"\"\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, observations, actions):\n",
    "        x = jnp.concatenate([observations, actions], axis=-1)\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=1)(x)\n",
    "        return jnp.squeeze(x, axis=-1)\n",
    "    \n",
    "class Actor(nn.Module):\n",
    "    \"\"\"actor model MLP\"\"\"\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=action_dim)(x)\n",
    "        x = nn.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b25a9a29",
   "metadata": {},
   "source": [
    "## Create necessary methods to the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a764cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random process N for action exploration\n",
    "def noise(noise_scale=0.1, key=key, action_dim=action_dim):\n",
    "    return noise_scale * jax.random.normal(key, (action_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca06c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the method to update model parameters\n",
    "\n",
    "# update critic\n",
    "@jax.jit\n",
    "def update_critic(model, states, actions, y):\n",
    "    def compute_critic_loss(params):\n",
    "        Q = model.apply_fn(params, states, actions)\n",
    "        return jnp.mean((Q - y)**2) #compute loss\n",
    "    \n",
    "    grad_fn = jax.grad(compute_critic_loss)\n",
    "    grads = grad_fn(model.params)\n",
    "    updated_model = model.apply_gradients(grads=grads)\n",
    "    return updated_model\n",
    "\n",
    "# udate actor\n",
    "@jax.jit\n",
    "def update_actor(model, states):\n",
    "    def compute_actor_loss(params):\n",
    "        actions = model.apply_fn(params, states)\n",
    "        return -jnp.mean(actions)  # Compute the actor loss\n",
    "    \n",
    "    grad_fn = jax.grad(compute_actor_loss)\n",
    "    grads = grad_fn(model.params)\n",
    "    updated_model = model.apply_gradients(grads=grads)\n",
    "    return updated_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc39eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the soft update function\n",
    "@jax.jit\n",
    "def soft_update(target_params, source_params, tau):\n",
    "    # Convert the source_params to a JAX-compatible data structure\n",
    "    source_params_tree = jtu.tree_map(lambda x: jnp.asarray(x), source_params)\n",
    "    target_params_tree = jtu.tree_map(lambda x: jnp.asarray(x), target_params)\n",
    "\n",
    "\n",
    "    # Compute the updated target parameters using a soft update\n",
    "    updated_params = jtu.tree_map(lambda x, y: tau * x + (1 - tau) * y, source_params_tree, target_params_tree)\n",
    "\n",
    "    return updated_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc9e8513",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af776785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                Actor Summary                                \u001b[0m\n",
      "┏━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                  \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│         │ Actor  │ - 1          │ \u001b[2mfloat32\u001b[0m[1]   │                          │\n",
      "│         │        │ - 2          │              │                          │\n",
      "├─────────┼────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ Dense_0 │ Dense  │ - 1          │ \u001b[2mfloat32\u001b[0m[256] │ bias: \u001b[2mfloat32\u001b[0m[256]       │\n",
      "│         │        │ - 2          │              │ kernel: \u001b[2mfloat32\u001b[0m[2,256]   │\n",
      "│         │        │              │              │                          │\n",
      "│         │        │              │              │ \u001b[1m768 \u001b[0m\u001b[1;2m(3.1 KB)\u001b[0m             │\n",
      "├─────────┼────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ Dense_1 │ Dense  │ \u001b[2mfloat32\u001b[0m[256] │ \u001b[2mfloat32\u001b[0m[256] │ bias: \u001b[2mfloat32\u001b[0m[256]       │\n",
      "│         │        │              │              │ kernel: \u001b[2mfloat32\u001b[0m[256,256] │\n",
      "│         │        │              │              │                          │\n",
      "│         │        │              │              │ \u001b[1m65,792 \u001b[0m\u001b[1;2m(263.2 KB)\u001b[0m        │\n",
      "├─────────┼────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ Dense_2 │ Dense  │ \u001b[2mfloat32\u001b[0m[256] │ \u001b[2mfloat32\u001b[0m[1]   │ bias: \u001b[2mfloat32\u001b[0m[1]         │\n",
      "│         │        │              │              │ kernel: \u001b[2mfloat32\u001b[0m[256,1]   │\n",
      "│         │        │              │              │                          │\n",
      "│         │        │              │              │ \u001b[1m257 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m             │\n",
      "├─────────┼────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m       Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m66,817 \u001b[0m\u001b[1;2m(267.3 KB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
      "└─────────┴────────┴──────────────┴──────────────┴──────────────────────────┘\n",
      "\u001b[1m                                                                             \u001b[0m\n",
      "\u001b[1m                     Total Parameters: 66,817 \u001b[0m\u001b[1;2m(267.3 KB)\u001b[0m\u001b[1m                     \u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[3m                                 Critic Summary                                 \u001b[0m\n",
      "┏━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                 \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│         │ Critic │ - \u001b[2mfloat32\u001b[0m[1,1] │ \u001b[2mfloat32\u001b[0m[1]     │                         │\n",
      "│         │        │ - \u001b[2mfloat32\u001b[0m[1,2] │                │                         │\n",
      "├─────────┼────────┼────────────────┼────────────────┼─────────────────────────┤\n",
      "│ Dense_0 │ Dense  │ \u001b[2mfloat32\u001b[0m[1,3]   │ \u001b[2mfloat32\u001b[0m[1,256] │ bias: \u001b[2mfloat32\u001b[0m[256]      │\n",
      "│         │        │                │                │ kernel: \u001b[2mfloat32\u001b[0m[3,256]  │\n",
      "│         │        │                │                │                         │\n",
      "│         │        │                │                │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m          │\n",
      "├─────────┼────────┼────────────────┼────────────────┼─────────────────────────┤\n",
      "│ Dense_1 │ Dense  │ \u001b[2mfloat32\u001b[0m[1,256] │ \u001b[2mfloat32\u001b[0m[1,256] │ bias: \u001b[2mfloat32\u001b[0m[256]      │\n",
      "│         │        │                │                │ kernel:                 │\n",
      "│         │        │                │                │ \u001b[2mfloat32\u001b[0m[256,256]        │\n",
      "│         │        │                │                │                         │\n",
      "│         │        │                │                │ \u001b[1m65,792 \u001b[0m\u001b[1;2m(263.2 KB)\u001b[0m       │\n",
      "├─────────┼────────┼────────────────┼────────────────┼─────────────────────────┤\n",
      "│ Dense_2 │ Dense  │ \u001b[2mfloat32\u001b[0m[1,256] │ \u001b[2mfloat32\u001b[0m[1,1]   │ bias: \u001b[2mfloat32\u001b[0m[1]        │\n",
      "│         │        │                │                │ kernel: \u001b[2mfloat32\u001b[0m[256,1]  │\n",
      "│         │        │                │                │                         │\n",
      "│         │        │                │                │ \u001b[1m257 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m            │\n",
      "├─────────┼────────┼────────────────┼────────────────┼─────────────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m67,073 \u001b[0m\u001b[1;2m(268.3 KB)\u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\n",
      "└─────────┴────────┴────────────────┴────────────────┴─────────────────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                      Total Parameters: 67,073 \u001b[0m\u001b[1;2m(268.3 KB)\u001b[0m\u001b[1m                       \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Randomly initialize critic network Q(s, a|θ_Q ) and actor μ(s|θ_μ ) with weights θ_Q and θ_μ .\n",
    "critic_params = Critic().init(key, jnp.zeros((1,action_dim)), jnp.zeros((1,state_dim)))\n",
    "actor_params = Actor().init(key, jnp.zeros((1, state_dim)))\n",
    "\n",
    "# define optimizers\n",
    "actor_optimizer = optax.adam(learning_rate=100)\n",
    "actor_opt_state = actor_optimizer.init(actor_params)\n",
    "\n",
    "critic_optimizer = optax.adam(learning_rate=100)\n",
    "critic_opt_state = critic_optimizer.init(critic_params)\n",
    "\n",
    "# Initialize the training state for flax porpuses\n",
    "critic = train_state.TrainState.create(\n",
    "    apply_fn=Critic().apply,\n",
    "    params=critic_params,\n",
    "    tx=critic_optimizer\n",
    ")\n",
    "\n",
    "actor = train_state.TrainState.create(\n",
    "    apply_fn=Actor().apply,\n",
    "    params=actor_params,\n",
    "    tx=actor_optimizer\n",
    ")\n",
    "\n",
    "print(Actor().tabulate(key, (1, state_dim) ))\n",
    "print(Critic().tabulate(key, jnp.ones((1,action_dim)), jnp.ones((1,state_dim))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4fede34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize target network Q_0_target and μ_0_target with weights θ_Q_target ← θ_Q , θ_μ_target ← θ_μ\n",
    "target_critic_params = critic_params\n",
    "target_actor_params = actor_params\n",
    "\n",
    "# Initialize the training state for flax porpuses\n",
    "target_critic = train_state.TrainState.create(\n",
    "    apply_fn=Critic().apply,\n",
    "    params=target_critic_params,\n",
    "    tx=critic_optimizer\n",
    ")\n",
    "\n",
    "target_actor = train_state.TrainState.create(\n",
    "    apply_fn=Actor().apply,\n",
    "    params=target_actor_params,\n",
    "    tx=actor_optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f4b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize replay buffer R\n",
    "buffer_size = 100000\n",
    "batch_size = 10\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, buffer_size, batch_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer = deque(maxlen=self.buffer_size)\n",
    "\n",
    "    def add(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def sample_batch(self):\n",
    "        indices = jax.random.choice(key, len(self.buffer), shape=(self.batch_size,), replace=True)\n",
    "        batch = [self.buffer[i] for i in indices]\n",
    "\n",
    "        return zip(*batch)\n",
    "    \n",
    "buffer = ReplayBuffer(buffer_size, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "670e041a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:13<06:27, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 0 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:22<05:04, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 1 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:31<04:35, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 2 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:41<04:15,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 3 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:50<04:02,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 4 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:59<03:50,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 5 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [01:10<03:50, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 6 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [01:20<03:34,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 7 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [01:29<03:19,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 8 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [01:37<03:04,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 9 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [01:46<02:52,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 10 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [01:55<02:43,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 11 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [02:04<02:36,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 12 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [02:17<02:41, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 13 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [02:27<02:31, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 14 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [02:36<02:16,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 15 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [02:46<02:08,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 16 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [02:55<01:56,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 17 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [03:05<01:45,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 18 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [03:14<01:34,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 19 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [03:23<01:24,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 20 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [03:32<01:14,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 21 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [03:41<01:05,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 22 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [03:51<00:56,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 23 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [04:00<00:47,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 24 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [04:09<00:37,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 25 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [04:19<00:27,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 26 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [04:28<00:18,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 27 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [04:37<00:09,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 28 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [04:46<00:00,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Episode: 29 Average reward: -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "episodes = 30\n",
    "T = 100\n",
    "gamma = 0.1\n",
    "tau = 0.001\n",
    "\n",
    "env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "episodes_reward = []\n",
    "\n",
    "for i in tqdm(range(episodes)):\n",
    "    # Initialize a random process N for action exploration\n",
    "    N = noise(0.1)\n",
    "    # Receive initial observation state s 1\n",
    "    state, info = env.reset(seed=seed)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        # Select action a_t = μ(s t |θ μ ) + N t according to the current policy and exploration noise\n",
    "        action = noise() + actor.apply_fn(actor.params, state)\n",
    "\n",
    "        # Execute action a t and observe reward r t and observe new state s t+1\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        # Store transition (s t , a t , r t , s t+1 ) in R\n",
    "        transition = (state, action, reward, observation)\n",
    "\n",
    "        # buffer.append(transition)\n",
    "        buffer.add(transition)\n",
    "\n",
    "        # Sample a random minibatch of N transitions (s i , a i , r i , s i+1 ) from R\n",
    "        states, actions, rewards, next_states = buffer.sample_batch()\n",
    "\n",
    "        # Set y = r  + γQ^0 (s_{i+1} , μ^0 (s_{i+1} |θ^μ )|θ^Q ) P\n",
    "        target_action = target_actor.apply_fn(target_actor_params, next_states)\n",
    "        target_q = target_critic.apply_fn(target_critic_params, jnp.asarray(next_states), jnp.asarray(target_action))\n",
    "\n",
    "        y = reward + gamma * (1 - terminated) * target_q\n",
    "\n",
    "        # Update critic by minimizing the loss\n",
    "        critic = update_critic(critic, jnp.asarray(states), jnp.asarray(actions), jnp.asarray(y))\n",
    "\n",
    "        # Update the actor policy using the sampled gradient:\n",
    "        actor = update_actor(actor, jnp.asarray(states))\n",
    "\n",
    "        # Update the target networks:\n",
    "        target_actor_params = soft_update(target_actor_params, actor.params, tau)\n",
    "        target_critic_params = soft_update(target_critic_params, critic.params, tau)\n",
    "       \n",
    "        # update if the environment is done and the current observation\n",
    "        done = terminated or truncated\n",
    "        # state = observation\n",
    "\n",
    "\n",
    "    episodes_reward.append(env.return_queue[-1])\n",
    "    \n",
    "    avg_reward = int(np.mean(env.return_queue))\n",
    "    print(\"Episode:\", i, \"Average reward:\", avg_reward)\n",
    "\n",
    "    \n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496fd34a",
   "metadata": {},
   "source": [
    "## Visualizing the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "217629c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards_to_plot = [rewards for rewards in episodes_reward]\n",
    "\n",
    "plt.plot(range(episodes), episodes_reward)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Rewards over episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c8e8a",
   "metadata": {},
   "source": [
    "## Stable baselines training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d9b4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cb3097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.429   |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 66       |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 1000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0379   |\n",
      "|    critic_loss     | 4.14e-08 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 800      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.264   |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 57       |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 2000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0358   |\n",
      "|    critic_loss     | 1.74e-08 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.21    |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 53       |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 3000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.034    |\n",
      "|    critic_loss     | 3.25e-08 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.182   |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 77       |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0328   |\n",
      "|    critic_loss     | 4.19e-07 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.164   |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 98       |\n",
      "|    total_timesteps | 5000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0317   |\n",
      "|    critic_loss     | 3.42e-07 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.153   |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 117      |\n",
      "|    total_timesteps | 6000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0299   |\n",
      "|    critic_loss     | 3.66e-06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.143   |\n",
      "| time/              |          |\n",
      "|    episodes        | 70       |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 137      |\n",
      "|    total_timesteps | 7000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0279   |\n",
      "|    critic_loss     | 1e-07    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.138   |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 156      |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0268   |\n",
      "|    critic_loss     | 2.57e-07 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.134   |\n",
      "| time/              |          |\n",
      "|    episodes        | 90       |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 175      |\n",
      "|    total_timesteps | 9000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0254   |\n",
      "|    critic_loss     | 3.96e-08 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -0.13    |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 194      |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0242   |\n",
      "|    critic_loss     | 1.46e-07 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9800     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Wrapper.render() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m action, _states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(obs)\n\u001b[1;32m     17\u001b[0m obs, rewards, dones, info \u001b[39m=\u001b[39m vec_env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m---> 18\u001b[0m env\u001b[39m.\u001b[39;49mrender(\u001b[39m\"\u001b[39;49m\u001b[39mhuman\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Wrapper.render() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# The noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"ddpg_MountainCarContinuous\")\n",
    "vec_env = model.get_env()\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpg_MountainCarContinuous\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    env.render(\"human\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
